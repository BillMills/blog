---
layout: post
title:  "What & How: Lessons Learned from Software Carpentry Instructor Training"
date:   2015-01-09
permalink: lessons-from-swc-instructor-training
---

*This post originally appeared on the Mozilla Science Lab's blog.*

The latest round of Software Carpentry &amp; Data Carpentry Instructor Training just wrapped at UC Davis this Wednesday, hosted by <a title="titusBrown" href="https://twitter.com/ctitusbrown" target="_blank">Titus Brown</a> and lead by <a title="gregWilson" href="https://twitter.com/gvwilson" target="_blank">Greg Wilson</a>, <a title="tracyTeal" href="https://twitter.com/tracykteal" target="_blank">Tracy Teal</a>, <a title="aleksandraPawlik" href="https://twitter.com/aleksandrana" target="_blank">Aleksandra Pawlik</a> and myself; as always, our great gratitude goes out to all our students - someday I hope I can teach you as much as you teach me.

Davis was the latest and last (for now) in a grand tour of live Instructor Training events that started at the <a title="uva" href="http://wp.mozillascience.org/creating-instruction-notes-from-uva-swc-teacher-training/" target="_blank">University of Virginia</a> last fall, and traveled to <a title="tgac" href="http://www.tgac.ac.uk/" target="_blank">The Genome Analysis Centre</a> in Norwich, England, the eScience Center at the <a title="escience" href="http://wp.mozillascience.org/train-the-trainers-next-iterations/" target="_blank">University of Washington</a>, and concluded with this latest stop in California. I had the enormous privilege of attending, helping, co-instructing and contributing to this push not only to spin up new Software and Data Carpentry instructors, but to refine our lessons and reflect on how we can set new instructors up to succeed. I learned a tremendous amount from teaching with Greg and all of our colleagues; on the plane back to Vancouver, I find myself reflecting on the opportunity for perspective they afforded me.

I like abstraction; it provides quiet unity to noisy fields of instance, and it helps in exploring purpose and motivation. But what I have come to hear people asking for is not just an elegant universe of pedagogy, but communities of practice stemming from an appetite for a maker movement made for the sciences, focused on craftspersonship and unflinchingly practical. In hindsight, it was this 'what' and 'how' of instructor training that we've been reaching for and iterating on for months now, and it consists of exploring <em>procedure</em>, <em>purpose</em> and <em>method</em>.

Right from our first stop in Virginia, the most common questions were on the procedure of workshops, as I've written about <a title="instructorFeedback" href="http://wp.mozillascience.org/starting-instruction-feedback-from-the-new-instructor-community/" target="_blank">previously</a>: 'how do I set up and prepare for a workshop?', 'what is the canonical content of Software Carpentry and how much of it should we cover?', 'what are the most common pitfalls when conducting a workshop?' - instructors want a clear roadmap for navigating the details, which is why I have pushed for an Instructor's Guide, and why Tracy Teal began walking new instructors through the simplest routes to making pull requests on our materials in Seattle, and Aleksandra Pawlik introduced website setup procedures to instructors this week at Davis. These activities were well-received and are shedding light on the procedures in question; at the <a title="resbazConf" href="http://resbaz.tumblr.com/conference" target="_blank">Research Bazaar</a>, we'll roll out even more new ideas to continue to shore up these procedural details so that instructors set out feeling confident in their task.

Another common question we received, was how to make sense of and actually use the pedagogical techniques we present; this caught my interest right away, and I dove in. I think I've clarified the purpose of the things we teach, by articulating their use in terms of the challenges we face; concept maps make our knowledge flexible when students need alternate explanations, formative assessment makes our lessons sensitive to student needs so we don't leave them behind, structured mental models enable our students to continue to practice after the workshop is done. But now that we've got the purpose of these tools, our new instructors at Davis rightly asked, 'how exactly do we use them to do that?' I think the final turn to these lessons (as always, for now) will be articulating exactly how to build concept maps, how to tease out a really deft multiple choice question, and how to adapt a lesson as student misconceptions come to light. I'm looking forward to tackling some of these questions in method with <a title="damienIrving" href="https://twitter.com/DrClimate" target="_blank">Damien Irving</a> next month in Melbourne at ResBaz.

I think we're zeroing in on something truly compelling for our instructors; we have procedure and purpose, and method will soon be in hand. It was a great opportunity for me personally to get to participate in this process; this conversation is the product of the whole Software and Data Carpentry community, and I can only synthesize the examples and needs and ideas that that community points to. I owe particular gratitude to Greg Wilson, who mentored me these last four Instructor Trainings by letting me co-pilot with him. This was an exercise not just in teaching pedagogy, but in empowering our colleagues to hold their ideas up in a way their students can run with; Greg accomplishes this by making those ideas approachable and human. This embodies exactly what we are trying to capture and export in Instructor Training, for which we couldn't have had a better example.